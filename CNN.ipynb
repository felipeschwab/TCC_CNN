{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a script I applied early in toe competition ~ LB = 3. With bounding box regression  \n",
    "# (applying this to fishes rather than whole images achieves a much better score)\n",
    "# I used this script to learn about CNNs, feature extraction and using features learned by the InceptionV3 CNN\n",
    "# to perform classificaiton using a SVM architecture.\n",
    "# Inspired (adapted heavily) from: http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import svm\n",
    "\n",
    "model_dir = 'model\\\\'\n",
    "images_dir = 'training_images\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    list_images = []\n",
    "    for path, subdirs, files in os.walk(images_dir):\n",
    "        for name in files:\n",
    "            if name.lower().endswith(\".jpg\"):\n",
    "                list_images.append(path+\"\\\\\"+name)\n",
    "            \n",
    "    features,labels = extract_features(list_images)\n",
    "\n",
    "    pickle.dump(features, open('features', 'wb'))\n",
    "    pickle.dump(labels, open('labels', 'wb'))\n",
    "    \n",
    "    #features = pickle.load(open('features', 'rb'))\n",
    "    #labels = pickle.load(open('labels', 'rb'))\n",
    "\n",
    "    # run a 10-fold CV SVM using probabilistic outputs. \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=0)\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "    clf.score(X_test, y_test)\n",
    "\n",
    "    # probabalistic SVM\n",
    "    clf =  CalibratedClassifierCV(clf, method='sigmoid', cv=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    k_fold = KFold(len(labels), shuffle=False, random_state=0)\n",
    "    C_array=[0.001,0.01,0.1,1,10]\n",
    "    C_scores=[]\n",
    "\n",
    "    #C = 0.1 is best\n",
    "\n",
    "    #clf = svm.LinearSVC(C=0.1)\n",
    "    clf = svm.SVC(kernel='linear', C=0.1,probability=True)\n",
    "\n",
    "    # final_model = clf.fit(features, labels)\n",
    "\n",
    "    final_model = CalibratedClassifierCV(clf,cv=10,method='sigmoid')\n",
    "    final_model = clf.fit(features, labels)\n",
    "\n",
    "    test_dir='test_images\\\\'\n",
    "    list_images = [test_dir+f for f in os.listdir(test_dir) if re.search('jpg|JPG', f)]\n",
    "    \n",
    "    features_test = extract_features2(list_images)\n",
    "\n",
    "    y_pred = final_model.predict_proba(features_test)\n",
    "\n",
    "    image_id = [i.split('\\\\')[-1] for i in list_images]#####\n",
    "\n",
    "    submit = open('submit.SVM.csv','w')\n",
    "    submit.write('image;BupInferior;BupSuperior;Formicidae_Inferior;Formicidae_Superior;MusInferior;MusSuperiorPentInferior;PentSuperior\\n')\n",
    "\n",
    "    for idx, id_n in enumerate(image_id):\n",
    "        probs=['%s' % p for p in list(y_pred[idx, :])]\n",
    "        submit.write('%s;%s\\n' % (str(image_id[idx]),';'.join(probs)))\n",
    "\n",
    "    submit.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "    with gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all features from pool layer of InceptionV3\n",
    "def extract_features(list_images):\n",
    "    nb_features = 2048\n",
    "    features = np.empty((len(list_images),nb_features))\n",
    "    labels = []\n",
    "    create_graph()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "        for ind, image in enumerate(list_images):\n",
    "            print('Processing %s...' % (image))\n",
    "            if not gfile.Exists(image):\n",
    "                tf.logging.fatal('File does not exist %s', image)\n",
    "            image_data = gfile.FastGFile(image, 'rb').read()    \n",
    "            predictions = sess.run(next_to_last_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "            features[ind,:] = np.squeeze(predictions)\n",
    "            labels.append(image.split('\\\\')[1]+'_'+image.split('\\\\')[2])\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features2(list_images):\n",
    "    nb_features = 2048\n",
    "    features = np.empty((len(list_images),nb_features))\n",
    "    create_graph()\n",
    "    with tf.Session() as sess:\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "        for ind, image in enumerate(list_images):\n",
    "            print('Processing %s...' % (image))\n",
    "            if not gfile.Exists(image):\n",
    "                tf.logging.fatal('File does not exist %s', image)\n",
    "            image_data = gfile.FastGFile(image, 'rb').read()\n",
    "            predictions = sess.run(next_to_last_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "            features[ind,:] = np.squeeze(predictions)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()\n",
    "print(\"fim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a script I applied early in toe competition ~ LB = 3. With bounding box regression  \n",
    "# (applying this to fishes rather than whole images achieves a much better score)\n",
    "# I used this script to learn about CNNs, feature extraction and using features learned by the InceptionV3 CNN\n",
    "# to perform classificaiton using a SVM architecture.\n",
    "# Inspired (adapted heavily) from: http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "#from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import svm\n",
    "\n",
    "model_dir = 'model/'\n",
    "# all training images\n",
    "images_dir = 'training_images/'\n",
    "list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]####\n",
    "\n",
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "\twith gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "\t\tgraph_def = tf.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(f.read())\n",
    "\t\t_ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "# extract all features from pool layer of InceptionV3\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tlabels = []\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\t\tlabels.append(re.split('-\\d+',image.split('/')[1])[0])#####\n",
    "\t\treturn features, labels\n",
    "\n",
    "\n",
    "features,labels = extract_features(list_images)\n",
    "\n",
    "pickle.dump(features, open('features', 'wb'))\n",
    "pickle.dump(labels, open('labels', 'wb'))\n",
    "\n",
    "#features = pickle.load(open('features', 'rb'))\n",
    "#labels = pickle.load(open('labels', 'rb'))\n",
    "\n",
    "# run a 10-fold CV SVM using probabilistic outputs. \n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, random_state=0)\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# probabalistic SVM\n",
    "clf =  CalibratedClassifierCV(clf, method='sigmoid', cv=2)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "\"\"\"\n",
    "### Funfou\n",
    "clf = LinearSVC(C=1.0, loss='squared_hinge', penalty='l2',multi_class='ovr')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true,y_pred):\n",
    "    cm_array = confusion_matrix(y_true,y_pred)\n",
    "    true_labels = np.unique(y_true)\n",
    "    pred_labels = np.unique(y_pred)\n",
    "    plt.imshow(cm_array[:-1,:-1], interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\", fontsize=16)\n",
    "    cbar = plt.colorbar(fraction=0.046, pad=0.04)\n",
    "    cbar.set_label('Number of images', rotation=270, labelpad=30, fontsize=12)\n",
    "    xtick_marks = np.arange(len(true_labels))\n",
    "    ytick_marks = np.arange(len(pred_labels))\n",
    "    plt.xticks(xtick_marks, true_labels, rotation=90)\n",
    "    plt.yticks(ytick_marks,pred_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label', fontsize=14)\n",
    "    plt.xlabel('Predicted label', fontsize=14)\n",
    "    fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "    fig_size[0] = 12\n",
    "    fig_size[1] = 12\n",
    "    plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "    \n",
    "print(\"Accuracy: {0:0.1f}%\".format(accuracy_score(y_test,y_pred)*100))\n",
    "plot_confusion_matrix(y_test,y_pred)\n",
    "\"\"\"\n",
    "\n",
    "k_fold = KFold(len(labels), shuffle=False, random_state=0)\n",
    "C_array=[0.001,0.01,0.1,1,10]\n",
    "C_scores=[]\n",
    "\n",
    "\"\"\"\n",
    "for k in C_array:\n",
    "\tclf = svm.SVC(kernel='linear', C=k)\n",
    "\tscores= cross_val_score(clf, features, labels, cv=k_fold, n_jobs=-1)\n",
    "\tC_scores.append(scores.mean())\n",
    "\tprint(C_scores)\n",
    "\"\"\"\n",
    "\n",
    "#C = 0.1 is best\n",
    "\n",
    "#clf = svm.LinearSVC(C=0.1)\n",
    "clf = svm.SVC(kernel='linear', C=0.1,probability=True)\n",
    "\n",
    "# final_model = clf.fit(features, labels)\n",
    "\n",
    "final_model = CalibratedClassifierCV(clf,cv=10,method='sigmoid')\n",
    "final_model = clf.fit(features, labels)\n",
    "\n",
    "\n",
    "test_dir='test_images/'\n",
    "list_images = [test_dir+f for f in os.listdir(test_dir) if re.search('jpg|JPG', f)]#####\n",
    "\n",
    "\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\treturn features\n",
    "\n",
    "\n",
    "features_test = extract_features(list_images)\n",
    "\n",
    "y_pred = final_model.predict_proba(features_test)\n",
    "#y_pred = final_model.predict(features_test)\n",
    "#y_pred = final_model.predict(features_test)\n",
    "    \n",
    "image_id = [i.split('/')[-1] for i in list_images]#####\n",
    "\n",
    "submit = open('submit.SVM.csv','w')\n",
    "submit.write('image;BupInferior;BupSuperior;Formicidae_Inferior;Formicidae_Superior;PentInferior;PentSuperior\\n')\n",
    "\n",
    "for idx, id_n in enumerate(image_id):\n",
    "\tprobs=['%s' % p for p in list(y_pred[idx, :])]\n",
    "\tsubmit.write('%s;%s\\n' % (str(image_id[idx]),';'.join(probs)))####\n",
    "\n",
    "submit.close()\n",
    "print(\"FIM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "\twith gfile.FastGFile(os.path.join(model_dir, 'output.pb'), 'rb') as f:\n",
    "\t\tgraph_def = tf.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(f.read())\n",
    "\t\t_ = tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "# extract all features from pool layer of InceptionV3\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tlabels = []\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\t\tlabels.append(re.split('_\\d+',image.split('/')[1])[0])\n",
    "\t\treturn features, labels\n",
    "\n",
    "\n",
    "features,labels = extract_features(list_images)\n",
    "\n",
    "pickle.dump(features, open('features', 'wb'))\n",
    "pickle.dump(labels, open('labels', 'wb'))\n",
    "\n",
    "features = pickle.load(open('features'))\n",
    "labels = pickle.load(open('labels'))\n",
    "\n",
    "# run a 10-fold CV SVM using probabilistic outputs. \n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, labels, test_size=0.1, random_state=0)\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "# probabalistic SVM\n",
    "clf =  sklearn.calibration.CalibratedClassifierCV(svm)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "\n",
    "k_fold = KFold(len(labels),n_folds=10, shuffle=False, random_state=0)\n",
    "C_array=[0.001,0.01,0.1,1,10]\n",
    "C_scores=[]\n",
    "\n",
    "for k in C_array:\n",
    "\tclf = svm.SVC(kernel='linear', C=k)\n",
    "\tscores= cross_val_score(clf, features, labels, cv=k_fold, n_jobs=-1)\n",
    "\tC_scores.append(scores.mean())\n",
    "\tprint C_scores\n",
    "\n",
    "#C = 0.1 is best\n",
    "\n",
    "#clf = svm.LinearSVC(C=0.1)\n",
    "clf = svm.SVC(kernel='linear', C=0.1,probability=True)\n",
    "\n",
    "# final_model = clf.fit(features, labels)\n",
    "\n",
    "final_model = CalibratedClassifierCV(clf,cv=10,method='sigmoid')\n",
    "final_model = clf.fit(features, labels)\n",
    "\n",
    "\n",
    "test_dir='latest_submission/test_stg1/test_stg1/'\n",
    "list_images = [test_dir+f for f in os.listdir(test_dir) if re.search('jpg|JPG', f)]\n",
    "\n",
    "\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\treturn features\n",
    "\n",
    "\n",
    "features_test = extract_features(list_images)\n",
    "\n",
    "y_pred = final_model.predict_proba(features_test)\n",
    "#y_pred = final_model.predict(features_test)\n",
    "#y_pred = final_model.predict(features_test)\n",
    "\n",
    "\n",
    "image_id = [i.split('/')[3] for i in list_images]\n",
    "\n",
    "submit = open('submit.SVM.csv','w')\n",
    "submit.write('image,ALB,BET,DOL,LAG,NoF,OTHER,SHARK,YFT\\n')\n",
    "\n",
    "for idx, id_n in enumerate(image_id):\n",
    "\tprobs=['%s' % p for p in list(y_pred[idx, :])]\n",
    "\tsubmit.write('%s,%s\\n' % (str(image_id[idx]),','.join(probs)))\n",
    "\n",
    "submit.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
