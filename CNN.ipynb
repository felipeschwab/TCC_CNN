{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_validate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, log_loss, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import pickle\n",
    "\n",
    "import cv2\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'model/'\n",
    "# all training images\n",
    "images_dir = 'training_images/'\n",
    "list_images = [images_dir+f for f in os.listdir(images_dir) if re.search('jpg|JPG', f)]####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup tensorFlow graph initiation\n",
    "def create_graph():\n",
    "\twith gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "\t\tgraph_def = tf.GraphDef()\n",
    "\t\tgraph_def.ParseFromString(f.read())\n",
    "\t\t_ = tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all features from pool layer of InceptionV3\n",
    "def extract_features(list_images):\n",
    "\tnb_features = 2048\n",
    "\tfeatures = np.empty((len(list_images),nb_features))\n",
    "\tlabels = []\n",
    "\tcreate_graph()\n",
    "\twith tf.Session() as sess:\n",
    "\t\tnext_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\t\tprint(next_to_last_tensor)\n",
    "\t\tfor ind, image in enumerate(list_images):\n",
    "\t\t\tprint('Processing %s...' % (image))\n",
    "\t\t\tif not gfile.Exists(image):\n",
    "\t\t\t\ttf.logging.fatal('File does not exist %s', image)\n",
    "\t\t\timage_data = gfile.FastGFile(image, 'rb').read()\n",
    "\t\t\tpredictions = sess.run(next_to_last_tensor,\n",
    "\t\t\t{'DecodeJpeg/contents:0': image_data})\n",
    "\t\t\tfeatures[ind,:] = np.squeeze(predictions)\n",
    "\t\t\tlabels.append(re.split('-\\d+',image.split('/')[1])[0])#####\n",
    "\t\treturn features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features,labels = extract_features(list_images)\n",
    "\n",
    "#pickle.dump(features, open('features', 'wb'))\n",
    "#pickle.dump(labels, open('labels', 'wb'))\n",
    "\n",
    "features = pickle.load(open('features', 'rb'))\n",
    "labels = pickle.load(open('labels', 'rb'))\n",
    "\n",
    "# run a 10-fold CV SVM using probabilistic outputs. \n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(features, labels, test_size=0.10)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=0.1,probability=True)\n",
    "final_model = CalibratedClassifierCV(clf,cv=10,method='sigmoid')\n",
    "final_model = clf.fit(Xtrain, ytrain)\n",
    "\n",
    "#Nome e ordem das categorias da CNN\n",
    "cat = final_model.classes_\n",
    "\n",
    "ypreds = final_model.predict_proba(Xtest)\n",
    "ypred_label = final_model.predict(Xtest)\n",
    "\n",
    "print(\"Loss após treino : \", log_loss(ytest, ypreds, eps=1e-15, normalize=True))\n",
    "\n",
    "\n",
    "######### CROSS VALIDATION ############\n",
    "CV = cross_validate(final_model,features, labels, cv=6)\n",
    "print(\"Test Scores após Cross validation: \", CV['test_score'])\n",
    "\n",
    "######### MATRIZ CONFUSAO ################\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(ytest, ypred_label)\n",
    "np.set_printoptions(precision=2)    \n",
    "    \n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=cat, normalize=True,title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "######### ANALISE DE CLASSIFICACAO ##############\n",
    "#print(classification_report(ytest, ypred_label, target_names=cat))\n",
    "\n",
    "with open('Final_Model.pkl', 'wb') as fid:\n",
    "    pickle.dump(final_model, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
